{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Online Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I955gdD8HR7K",
        "colab_type": "text"
      },
      "source": [
        "#Online Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU9sIMW3HKKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Handles creme instalation\n",
        "!pip install creme"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhkO8W90TLfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Takes care of basic imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers.core import Dense, Activation\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.models import load_model\n",
        "\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "      if x != target:\n",
        "        result.append(x)\n",
        "    res1 = df[result].values \n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return res1.astype(np.float32), dummies.to_numpy().astype(np.float32)\n",
        "    else:\n",
        "        return res1.astype(np.float32), df[target].to_numpy().astype(np.float32)\n",
        "\n",
        "\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1, data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
        "               * (normalized_high - normalized_low) + normalized_low\n",
        "\n",
        "ENCODING = 'utf-8'\n",
        "\n",
        "def expand_categories(values):\n",
        "    result = []\n",
        "    s = values.value_counts()\n",
        "    t = float(len(values))\n",
        "    for v in s.index:\n",
        "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
        "    return \"[{}]\".format(\",\".join(result))\n",
        "\n",
        "def analyze(filename):\n",
        "    print()\n",
        "    print(\"Analyzing: {}\".format(filename))\n",
        "    df = pd.read_csv(filename,encoding=ENCODING,low_memory=False)\n",
        "    cols = df.columns.values\n",
        "    total = float(len(df))\n",
        "\n",
        "    print(\"{} rows\".format(int(total)))\n",
        "    i = 0\n",
        "    for col in cols:\n",
        "        name = df.columns[i]\n",
        "        uniques = df[col].unique()\n",
        "        unique_count = len(uniques)\n",
        "        if unique_count>100:\n",
        "            print(\"--> {}: {} ({}%)\".format(name, unique_count,int(((unique_count)/total)*100)))\n",
        "        else:\n",
        "            print(\"--> {}: {}\".format(name, expand_categories(df[col])))\n",
        "            expand_categories(df[col])\n",
        "        i += 1\n",
        "\n",
        "def analyze_df(dataframe):\n",
        "    print()\n",
        "    df = dataframe\n",
        "    cols = df.columns.values\n",
        "    total = float(len(df))\n",
        "    print(\"{} rows\".format(int(total)))\n",
        "    i = 0\n",
        "    for col in cols:\n",
        "        name = col_names[i]\n",
        "        uniques = df[col].unique()\n",
        "        unique_count = len(uniques)\n",
        "        if unique_count>100:\n",
        "            print(\"--> {}: {} ({}%)\".format(name, unique_count,int(((unique_count)/total)*100)))\n",
        "        else:\n",
        "            print(\"--> {}: {}\".format(name, expand_categories(df[col])))\n",
        "            expand_categories(df[col])\n",
        "        if i < 48:\n",
        "          i += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or_jOoA2Hts_",
        "colab_type": "text"
      },
      "source": [
        "##ONLINE LEARNING: UNSW-NB15 (ALL FEATURES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPkzFaTgH8dd",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVKdPIgGAyeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_names = [\n",
        "    'srcip', 'sport', 'dstip', 'dsport','proto','state','dur','sbytes',\n",
        "    'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
        "    'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz',\n",
        "    'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt',\n",
        "    'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
        "    'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst',\n",
        "    'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm','ct_dst_sport_ltm',\n",
        "    'ct_dst_src_ltm','attack_cat', 'label'\n",
        "]\n",
        "\n",
        "#Imports the dataset\n",
        "df1 = pd.read_csv('UNSW-NB15_1.csv', header=0, names=col_names)\n",
        "df2 = pd.read_csv('UNSW-NB15_2.csv', header=0, names=col_names)\n",
        "df3 = pd.read_csv('UNSW-NB15_3.csv', header=0, names=col_names)\n",
        "df4 = pd.read_csv('UNSW-NB15_4.csv', header=0, names=col_names)\n",
        "df = pd.concat([df1,df2,df3,df4], ignore_index = True)\n",
        "\n",
        "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "#Corrects the dataset\n",
        "for name in col_names:\n",
        "  if name == 'sport' or name == 'dsport':\n",
        "    df[name].replace('-', np.nan, inplace=True)\n",
        "    index = 0\n",
        "    for i in df[name]:\n",
        "      istr = str(i)\n",
        "      if isinstance(i, str) and '0x' in istr:\n",
        "        x = int(i, 16)\n",
        "        df.at[index, name] = x\n",
        "      index += 1\n",
        "  if name == 'service':\n",
        "    df[name].replace('-', np.nan, inplace=True)\n",
        "\n",
        "df['sport'] = pd.to_numeric(df['sport'])\n",
        "df['dsport'] = pd.to_numeric(df['dsport'])\n",
        "df['ct_ftp_cmd'] = pd.to_numeric(df['ct_ftp_cmd'])\n",
        "\n",
        "for name in col_names:\n",
        "    if name == 'srcip' or name == 'dstip' or name == 'proto' or name == 'state' or name == 'service':\n",
        "        df[name].fillna(\"None\", inplace=True)\n",
        "    elif name == 'attack_cat':\n",
        "        df['attack_cat'].fillna(\"Not an Attack\", inplace=True)\n",
        "        continue\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "#Time to encode\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "encode_text_dummy(df, 'srcip')\n",
        "encode_text_index(df,'sport')\n",
        "encode_text_dummy(df, 'dstip')\n",
        "encode_text_index(df,'dsport')\n",
        "encode_text_dummy(df, 'proto')\n",
        "encode_text_dummy(df, 'state')\n",
        "encode_numeric_zscore(df,'dur')\n",
        "encode_numeric_zscore(df,'sbytes')\n",
        "encode_numeric_zscore(df,'dbytes')\n",
        "encode_numeric_zscore(df,'sttl')\n",
        "encode_numeric_zscore(df,'dttl')\n",
        "encode_numeric_zscore(df,'sloss')\n",
        "encode_numeric_zscore(df,'dloss')\n",
        "encode_text_dummy(df, 'service')\n",
        "encode_numeric_zscore(df,'Sload')\n",
        "encode_numeric_zscore(df,'Dload')\n",
        "encode_numeric_zscore(df,'Spkts')\n",
        "encode_numeric_zscore(df,'Dpkts')\n",
        "encode_numeric_zscore(df,'swin')\n",
        "encode_numeric_zscore(df,'dwin')\n",
        "encode_numeric_zscore(df,'stcpb')\n",
        "encode_numeric_zscore(df,'dtcpb')\n",
        "encode_numeric_zscore(df,'smeansz')\n",
        "encode_numeric_zscore(df,'dmeansz')\n",
        "encode_numeric_zscore(df,'trans_depth')\n",
        "encode_numeric_zscore(df,'res_bdy_len')\n",
        "encode_numeric_zscore(df,'Sjit')\n",
        "encode_numeric_zscore(df,'Djit')\n",
        "encode_numeric_zscore(df,'Sintpkt')\n",
        "encode_numeric_zscore(df,'Dintpkt')\n",
        "encode_numeric_zscore(df,'tcprtt')\n",
        "encode_numeric_zscore(df,'synack')\n",
        "encode_numeric_zscore(df,'ackdat')\n",
        "#encode_text_dummy(df, 'is_sm_ips_ports') #added\n",
        "encode_numeric_zscore(df,'ct_state_ttl')\n",
        "encode_numeric_zscore(df,'ct_flw_http_mthd')\n",
        "#encode_text_dummy(df, 'is_ftp_login') #added\n",
        "encode_text_index(df,'ct_ftp_cmd') #encode_numeric_zscore(df,'ct_ftp_cmd') \n",
        "encode_numeric_zscore(df,'ct_srv_src')\n",
        "encode_numeric_zscore(df,'ct_srv_dst')\n",
        "encode_numeric_zscore(df,'ct_dst_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_ ltm')\n",
        "encode_numeric_zscore(df,'ct_src_dport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_sport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_src_ltm')\n",
        "\n",
        "df.drop('attack_cat', axis=1, inplace=True)\n",
        "# display 5 rows\n",
        "df.dropna(inplace=True, axis=0) # For now, just drop NA's (rows with missing values)\n",
        "x_columns = df.columns.drop('label')\n",
        "x = df[x_columns]\n",
        "y = df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lb-haAVIGuT",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtWUgSYH_GXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import stream, datasets, compose, linear_model, metrics\n",
        "#Creates the sequential stream for online learning\n",
        "dataset = stream.iter_pandas(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tht5hY9Ic174",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = metrics.Accuracy()\n",
        "conf = metrics.ConfusionMatrix()\n",
        "rec = metrics.Recall()\n",
        "roc = metrics.ROCAUC()\n",
        "f1 = metrics.F1()\n",
        "pre = metrics.Precision()\n",
        "classifier = linear_model.LogisticRegression()\n",
        "n = 0\n",
        "for x, y in dataset:\n",
        "  y_pred = classifier.predict_one(x)\n",
        "  classifier.fit_one(x, y)\n",
        "  acc.update(y, y_pred)\n",
        "  conf.update(y,y_pred)\n",
        "  rec.update(y,y_pred)\n",
        "  roc.update(y,y_pred)\n",
        "  f1.update(y,y_pred)\n",
        "  pre.update(y,y_pred)\n",
        "  if n%10000 == 0: #Limits output on console to avoid unexpected crashes\n",
        "    print(\"[INFO] update {} - {}\".format(n, acc))\n",
        "  n+=1\n",
        "print(acc)\n",
        "print(conf)\n",
        "print(rec)\n",
        "print(roc)\n",
        "print(f1)\n",
        "print(pre)\n",
        "matrix = [[conf[0][0],conf[0][1]],\n",
        "          [conf[1][0],conf[1][1]]]\n",
        "labels = [0,1]\n",
        "df_cm = pd.DataFrame(matrix, index = [i for i in labels],\n",
        "                  columns = [i for i in labels])\n",
        "plt.figure(figsize = (5,3))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFb2gAM48DWu",
        "colab_type": "text"
      },
      "source": [
        "##ONLINE LEARNING USING THE RELEVANT FEATURES IN UNSW-NB15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA-VP21wI7i-",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqaI3V1zvkM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_names = [\n",
        "    'srcip', 'sport', 'dstip', 'dsport','proto','state','dur','sbytes',\n",
        "    'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
        "    'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz',\n",
        "    'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt',\n",
        "    'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
        "    'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst',\n",
        "    'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm','ct_dst_sport_ltm',\n",
        "    'ct_dst_src_ltm','attack_cat', 'label'\n",
        "]\n",
        "#Imports the dataset\n",
        "df1 = pd.read_csv('UNSW-NB15_1.csv', header=0, names=col_names)\n",
        "df2 = pd.read_csv('UNSW-NB15_2.csv', header=0, names=col_names)\n",
        "df3 = pd.read_csv('UNSW-NB15_3.csv', header=0, names=col_names)\n",
        "df4 = pd.read_csv('UNSW-NB15_4.csv', header=0, names=col_names)\n",
        "df = pd.concat([df1,df2,df3,df4], ignore_index = True)\n",
        "\n",
        "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "for name in col_names:\n",
        "  if name == 'sport' or name == 'dsport':\n",
        "    df[name].replace('-', np.nan, inplace=True)\n",
        "    index = 0\n",
        "    for i in df[name]:\n",
        "      istr = str(i)\n",
        "      if isinstance(i, str) and '0x' in istr:\n",
        "        x = int(i, 16)\n",
        "        df.at[index, name] = x\n",
        "      index += 1\n",
        "\n",
        "df['sport'] = pd.to_numeric(df['sport'])\n",
        "df['dsport'] = pd.to_numeric(df['dsport'])\n",
        "df['ct_ftp_cmd'] = pd.to_numeric(df['ct_ftp_cmd'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itsZlPOsvrVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding the dataset\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "df.drop('srcip', axis=1, inplace=True)\n",
        "df.drop('sport', axis=1, inplace=True)\n",
        "df.drop('dstip', axis=1, inplace=True)\n",
        "df.drop('dsport', axis=1, inplace=True)\n",
        "encode_text_index(df, 'proto')\n",
        "encode_text_index(df, 'state')\n",
        "encode_numeric_zscore(df,'dur')\n",
        "encode_numeric_zscore(df,'sbytes')\n",
        "encode_numeric_zscore(df,'dbytes')\n",
        "encode_numeric_zscore(df,'sttl')\n",
        "encode_numeric_zscore(df,'dttl')\n",
        "encode_numeric_zscore(df,'sloss')\n",
        "encode_numeric_zscore(df,'dloss')\n",
        "encode_text_index(df, 'service')\n",
        "encode_numeric_zscore(df,'Sload')\n",
        "encode_numeric_zscore(df,'Dload')\n",
        "encode_numeric_zscore(df,'Spkts')\n",
        "encode_numeric_zscore(df,'Dpkts')\n",
        "encode_numeric_zscore(df,'swin')\n",
        "encode_numeric_zscore(df,'dwin')\n",
        "encode_numeric_zscore(df,'stcpb')\n",
        "encode_numeric_zscore(df,'dtcpb')\n",
        "encode_numeric_zscore(df,'smeansz')\n",
        "encode_numeric_zscore(df,'dmeansz')\n",
        "encode_numeric_zscore(df,'trans_depth')\n",
        "encode_numeric_zscore(df,'res_bdy_len')\n",
        "encode_numeric_zscore(df,'Sjit')\n",
        "encode_numeric_zscore(df,'Djit')\n",
        "encode_numeric_zscore(df,'Sintpkt')\n",
        "encode_numeric_zscore(df,'Dintpkt')\n",
        "encode_numeric_zscore(df,'tcprtt')\n",
        "encode_numeric_zscore(df,'synack')\n",
        "encode_numeric_zscore(df,'ackdat')\n",
        "\n",
        "encode_numeric_zscore(df,'ct_state_ttl')\n",
        "encode_numeric_zscore(df,'ct_flw_http_mthd')\n",
        "encode_text_index(df, 'is_ftp_login')\n",
        "encode_text_index(df,'ct_ftp_cmd')\n",
        "encode_numeric_zscore(df,'ct_srv_src')\n",
        "encode_numeric_zscore(df,'ct_srv_dst')\n",
        "encode_numeric_zscore(df,'ct_dst_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_dport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_sport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_src_ltm')\n",
        "\n",
        "df.drop('attack_cat', axis=1, inplace=True)\n",
        "df.dropna(inplace=True, axis=0) # For now, just drop NA's (rows with missing values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzx9hqLywr6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = to_xy(df, 'label')\n",
        "x_columns = ['sttl', 'Dload', 'Spkts', 'sloss', 'dloss', 'ct_src_ ltm', 'ct_src_ ltm',\n",
        "             'ct_srv_dst']\n",
        "x = df[x_columns]\n",
        "y = df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS6B2hU9JNYr",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF6--i89wYsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import stream, datasets, compose, linear_model, metrics\n",
        "\n",
        "#Creates the needed sequential stream from the dataset\n",
        "dataset = stream.iter_pandas(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VI9mbv6wiiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import multiclass\n",
        "#Trains the model, gets metrics and confusion matrix\n",
        "acc = metrics.Accuracy()\n",
        "conf = metrics.ConfusionMatrix()\n",
        "rec = metrics.Recall()\n",
        "roc = metrics.ROCAUC()\n",
        "f1 = metrics.F1()\n",
        "pre = metrics.Precision()\n",
        "classifier = linear_model.LogisticRegression()\n",
        "n = 0\n",
        "for x, y in dataset:\n",
        "  y_pred = classifier.predict_one(x)\n",
        "  classifier.fit_one(x, y)\n",
        "  acc.update(y, y_pred)\n",
        "  conf.update(y,y_pred)\n",
        "  rec.update(y,y_pred)\n",
        "  roc.update(y,y_pred)\n",
        "  f1.update(y,y_pred)\n",
        "  pre.update(y,y_pred)\n",
        "  if n%10000 == 0: #Limits output on screen so as to not crash the shell\n",
        "    print(\"INFO update {} - {} - {} - {}\".format(n, acc, f1, roc))\n",
        "  n+=1\n",
        "  \n",
        "print(acc)\n",
        "print(conf)\n",
        "print(rec)\n",
        "print(roc)\n",
        "print(f1)\n",
        "print(pre)\n",
        "matrix = [[conf[0][0],conf[0][1]],\n",
        "          [conf[1][0],conf[1][1]]]\n",
        "labels = [0,1]\n",
        "df_cm = pd.DataFrame(matrix, index = [i for i in labels],\n",
        "                  columns = [i for i in labels])\n",
        "plt.figure(figsize = (5,3))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y32cOD5JpK4",
        "colab_type": "text"
      },
      "source": [
        "## Multiclass Online Learning UNSW-NB15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3OGOX8GJssX",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SVZrwbaVcuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_names = [\n",
        "    'srcip', 'sport', 'dstip', 'dsport','proto','state','dur','sbytes',\n",
        "    'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
        "    'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz',\n",
        "    'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt',\n",
        "    'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
        "    'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst',\n",
        "    'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm','ct_dst_sport_ltm',\n",
        "    'ct_dst_src_ltm','attack_cat', 'label'\n",
        "]\n",
        "#Imports the dataset\n",
        "df1 = pd.read_csv('UNSW-NB15_1.csv', header=0, names=col_names)\n",
        "df2 = pd.read_csv('UNSW-NB15_2.csv', header=0, names=col_names)\n",
        "df3 = pd.read_csv('UNSW-NB15_3.csv', header=0, names=col_names)\n",
        "df4 = pd.read_csv('UNSW-NB15_4.csv', header=0, names=col_names)\n",
        "df = pd.concat([df1,df2,df3,df4], ignore_index = True)\n",
        "\n",
        "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "for name in col_names:\n",
        "  if name == 'sport' or name == 'dsport':\n",
        "    df[name].replace('-', np.nan, inplace=True)\n",
        "    index = 0\n",
        "    for i in df[name]:\n",
        "      istr = str(i)\n",
        "      if isinstance(i, str) and '0x' in istr:\n",
        "        x = int(i, 16)\n",
        "        df.at[index, name] = x\n",
        "      index += 1\n",
        "\n",
        "df['sport'] = pd.to_numeric(df['sport'])\n",
        "df['dsport'] = pd.to_numeric(df['dsport'])\n",
        "df['ct_ftp_cmd'] = pd.to_numeric(df['ct_ftp_cmd'])\n",
        "print(\"done\")\n",
        "\n",
        "#Time to encode\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "df.drop('srcip', axis=1, inplace=True)\n",
        "df.drop('sport', axis=1, inplace=True)\n",
        "df.drop('dstip', axis=1, inplace=True)\n",
        "df.drop('dsport', axis=1, inplace=True)\n",
        "encode_text_index(df, 'proto')\n",
        "encode_text_index(df, 'state')\n",
        "encode_numeric_zscore(df,'dur')\n",
        "encode_numeric_zscore(df,'sbytes')\n",
        "encode_numeric_zscore(df,'dbytes')\n",
        "encode_numeric_zscore(df,'sttl')\n",
        "encode_numeric_zscore(df,'dttl')\n",
        "encode_numeric_zscore(df,'sloss')\n",
        "encode_numeric_zscore(df,'dloss')\n",
        "encode_text_index(df, 'service')\n",
        "encode_numeric_zscore(df,'Sload')\n",
        "encode_numeric_zscore(df,'Dload')\n",
        "encode_numeric_zscore(df,'Spkts')\n",
        "encode_numeric_zscore(df,'Dpkts')\n",
        "encode_numeric_zscore(df,'swin')\n",
        "encode_numeric_zscore(df,'dwin')\n",
        "encode_numeric_zscore(df,'stcpb')\n",
        "encode_numeric_zscore(df,'dtcpb')\n",
        "encode_numeric_zscore(df,'smeansz')\n",
        "encode_numeric_zscore(df,'dmeansz')\n",
        "encode_numeric_zscore(df,'trans_depth')\n",
        "encode_numeric_zscore(df,'res_bdy_len')\n",
        "encode_numeric_zscore(df,'Sjit')\n",
        "encode_numeric_zscore(df,'Djit')\n",
        "encode_numeric_zscore(df,'Sintpkt')\n",
        "encode_numeric_zscore(df,'Dintpkt')\n",
        "encode_numeric_zscore(df,'tcprtt')\n",
        "encode_numeric_zscore(df,'synack')\n",
        "encode_numeric_zscore(df,'ackdat')\n",
        "encode_numeric_zscore(df,'ct_state_ttl')\n",
        "encode_numeric_zscore(df,'ct_flw_http_mthd')\n",
        "encode_text_index(df, 'is_ftp_login')\n",
        "encode_text_index(df,'ct_ftp_cmd')\n",
        "encode_numeric_zscore(df,'ct_srv_src')\n",
        "encode_numeric_zscore(df,'ct_srv_dst')\n",
        "encode_numeric_zscore(df,'ct_dst_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_dport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_sport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_src_ltm')\n",
        "df['attack_cat'].fillna(\"Not an Attack\", inplace=True)\n",
        "df.drop('label', axis=1, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfuO7H097SSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_columns = ['sttl', 'Dload', 'Spkts', 'sloss', 'dloss', 'ct_src_ltm', 'ct_src_ltm',\n",
        "             'ct_srv_dst']\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['attack_cat'] = df['attack_cat'].astype('category')\n",
        "x = df[x_columns]\n",
        "y = df['attack_cat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6MDnnGgV59c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import stream, datasets, compose, linear_model, metrics\n",
        "\n",
        "#Creates the sequential stream needed\n",
        "dataset = stream.iter_pandas(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN37BWk3KInF",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmCwFWbKWswr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import multiclass\n",
        "acc = metrics.Accuracy()\n",
        "conf = metrics.ConfusionMatrix()\n",
        "rec = metrics.Recall()\n",
        "roc = metrics.ROCAUC()\n",
        "f1 = metrics.F1()\n",
        "pre = metrics.Precision()\n",
        "classifier = multiclass.OneVsRestClassifier(linear_model.LogisticRegression())\n",
        "n = 0\n",
        "for x, y in dataset:\n",
        "  y_pred = str(classifier.predict_one(x))\n",
        "  classifier.fit_one(x, y)\n",
        "\n",
        "  acc.update(y, y_pred)\n",
        "  conf.update(y,y_pred)\n",
        "  rec.update(y,y_pred)\n",
        "  f1.update(y,y_pred)\n",
        "  pre.update(y,y_pred)\n",
        "  if n%10000 == 0:\n",
        "    print(\"INFO update {} - {} - {}\".format(n, acc, f1))\n",
        "  n+=1\n",
        "  \n",
        "print(acc)\n",
        "print(rec)\n",
        "print(f1)\n",
        "print(pre)\n",
        "print(conf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a20w7hMbKl6l",
        "colab_type": "text"
      },
      "source": [
        "## ONLINE LEARNING KDD-99\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbKOXNCRKtkT",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB1c3TdtX3F6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing the dataset\n",
        "df = pd.read_csv(\"/content/drive/My Drive/TFG/kddcup.data.corrected\", header=None)\n",
        "df.columns = [\n",
        "    'duration', 'protocol_type', 'service','flag','src_bytes','dst_bytes',\n",
        "    'land','wrong_fragment','urgent','hot','num_failed_logins','logged_in',\n",
        "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
        "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
        "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
        "    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'outcome'\n",
        "]\n",
        "\n",
        "display(df[0:5])\n",
        "df.dropna(inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4u2OSxCYBxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding the dataset\n",
        "encode_numeric_zscore(df, 'duration')\n",
        "encode_text_dummy(df, 'protocol_type')\n",
        "encode_text_dummy(df, 'service')\n",
        "encode_text_dummy(df, 'flag')\n",
        "encode_numeric_zscore(df, 'src_bytes')\n",
        "encode_numeric_zscore(df, 'dst_bytes')\n",
        "encode_text_dummy(df, 'land')\n",
        "encode_numeric_zscore(df, 'wrong_fragment')\n",
        "encode_numeric_zscore(df, 'urgent')\n",
        "encode_numeric_zscore(df, 'hot')\n",
        "encode_numeric_zscore(df, 'num_failed_logins')\n",
        "encode_text_dummy(df, 'logged_in')\n",
        "encode_numeric_zscore(df, 'num_compromised')\n",
        "encode_numeric_zscore(df, 'root_shell')\n",
        "encode_numeric_zscore(df, 'su_attempted')\n",
        "encode_numeric_zscore(df, 'num_root')\n",
        "encode_numeric_zscore(df, 'num_file_creations')\n",
        "encode_numeric_zscore(df, 'num_shells')\n",
        "encode_numeric_zscore(df, 'num_access_files')\n",
        "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
        "encode_text_dummy(df, 'is_host_login')\n",
        "encode_text_dummy(df, 'is_guest_login')\n",
        "encode_numeric_zscore(df, 'count')\n",
        "encode_numeric_zscore(df, 'srv_count')\n",
        "encode_numeric_zscore(df, 'serror_rate')\n",
        "encode_numeric_zscore(df, 'srv_serror_rate')\n",
        "encode_numeric_zscore(df, 'rerror_rate')\n",
        "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
        "encode_numeric_zscore(df, 'same_srv_rate')\n",
        "encode_numeric_zscore(df, 'diff_srv_rate')\n",
        "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_count')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
        "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
        "\n",
        "df.dropna(inplace=True,axis=1)\n",
        "\n",
        "#Ensures the use of a binary label\n",
        "df['outcome'] = np.where(df['outcome']=='normal.', 0, 1)\n",
        "df['outcome'] = pd.to_numeric(df['outcome'])\n",
        "\n",
        "x_columns = df.columns.drop('outcome')\n",
        "x = df[x_columns]\n",
        "y = df['outcome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWWDbUQ8YGJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import stream, datasets, compose, linear_model, metrics\n",
        "\n",
        "#Creates the stream of data\n",
        "dataset = stream.iter_pandas(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOlP2WaDLV5p",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9nEUyseYKZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import multiclass\n",
        "acc = metrics.Accuracy()\n",
        "conf = metrics.ConfusionMatrix()\n",
        "rec = metrics.Recall()\n",
        "f1 = metrics.F1()\n",
        "pre = metrics.Precision()\n",
        "classifier = linear_model.LogisticRegression()\n",
        "n = 0\n",
        "for x, y in dataset:\n",
        "  y_pred = classifier.predict_one(x)\n",
        "  classifier.fit_one(x, y)\n",
        "  #Metrics\n",
        "  acc.update(y, y_pred)\n",
        "  conf.update(y,y_pred)\n",
        "  rec.update(y,y_pred)\n",
        "  f1.update(y,y_pred)\n",
        "  pre.update(y,y_pred)\n",
        "  if n%10000 == 0:\n",
        "    print(\"INFO] update {} - {}\".format(n, acc))\n",
        "  n+=1\n",
        "  \n",
        "print(acc)\n",
        "print(conf)\n",
        "print(rec)\n",
        "print(f1)\n",
        "print(pre)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h01naJolLioy",
        "colab_type": "text"
      },
      "source": [
        "##Multiclass Online Learning with KDD-99"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zznol5jLoOs",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LGAhJDjc8at",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------------------------------------------------CLASIFICACIÓN MULTICLASE PARA EL KDD-99-------------------------------------------\n",
        "df = pd.read_csv(\"/content/drive/My Drive/TFG/kddcup.data.corrected\", header=None)\n",
        "df.columns = [\n",
        "    'duration', 'protocol_type', 'service','flag','src_bytes','dst_bytes',\n",
        "    'land','wrong_fragment','urgent','hot','num_failed_logins','logged_in',\n",
        "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
        "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
        "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
        "    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'outcome'\n",
        "]\n",
        "\n",
        "df.dropna(inplace=True, axis=1)\n",
        "\n",
        "encode_numeric_zscore(df, 'duration')\n",
        "encode_text_dummy(df, 'protocol_type')\n",
        "encode_text_dummy(df, 'service')\n",
        "encode_text_dummy(df, 'flag')\n",
        "encode_numeric_zscore(df, 'src_bytes')\n",
        "encode_numeric_zscore(df, 'dst_bytes')\n",
        "encode_text_dummy(df, 'land')\n",
        "encode_numeric_zscore(df, 'wrong_fragment')\n",
        "encode_numeric_zscore(df, 'urgent')\n",
        "encode_numeric_zscore(df, 'hot')\n",
        "encode_numeric_zscore(df, 'num_failed_logins')\n",
        "encode_text_dummy(df, 'logged_in')\n",
        "encode_numeric_zscore(df, 'num_compromised')\n",
        "encode_numeric_zscore(df, 'root_shell')\n",
        "encode_numeric_zscore(df, 'su_attempted')\n",
        "encode_numeric_zscore(df, 'num_root')\n",
        "encode_numeric_zscore(df, 'num_file_creations')\n",
        "encode_numeric_zscore(df, 'num_shells')\n",
        "encode_numeric_zscore(df, 'num_access_files')\n",
        "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
        "encode_text_dummy(df, 'is_host_login')\n",
        "encode_text_dummy(df, 'is_guest_login')\n",
        "encode_numeric_zscore(df, 'count')\n",
        "encode_numeric_zscore(df, 'srv_count')\n",
        "encode_numeric_zscore(df, 'serror_rate')\n",
        "encode_numeric_zscore(df, 'srv_serror_rate')\n",
        "encode_numeric_zscore(df, 'rerror_rate')\n",
        "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
        "encode_numeric_zscore(df, 'same_srv_rate')\n",
        "encode_numeric_zscore(df, 'diff_srv_rate')\n",
        "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_count')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
        "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
        "\n",
        "df.dropna(inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29GdM36ddKij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_columns = df.columns.drop('outcome')\n",
        "x = df[x_columns]\n",
        "y = df['outcome']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJLPM9EmdMC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import stream, datasets, compose, linear_model, metrics\n",
        "\n",
        "#Creates the necessary sequential stream\n",
        "dataset = stream.iter_pandas(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCQ5zLwSMHBN",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDJShu9VdUxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from creme import multiclass\n",
        "#NOTE: The full KDD-99 dataset is huge. This will iterate through its entirety, but it's recommended to limit the for look to a chosen number of iterations.\n",
        "acc = metrics.Accuracy()\n",
        "conf = metrics.ConfusionMatrix()\n",
        "rec = metrics.Recall()\n",
        "f1 = metrics.F1()\n",
        "pre = metrics.Precision()\n",
        "classifier = multiclass.OneVsRestClassifier(linear_model.LogisticRegression())\n",
        "n = 0\n",
        "for x, y in dataset:\n",
        "  y_pred = str(classifier.predict_one(x))\n",
        "  classifier.fit_one(x, y)\n",
        "  acc.update(y, y_pred)\n",
        "  conf.update(y,y_pred)\n",
        "  rec.update(y,y_pred)\n",
        "  f1.update(y,y_pred)\n",
        "  pre.update(y,y_pred)\n",
        "  if n%10000 == 0:\n",
        "    print(\"INFO update {} - {} - {}\".format(n, acc, f1))\n",
        "  n+=1\n",
        "\n",
        "print(acc)\n",
        "print(conf)\n",
        "print(rec)\n",
        "print(f1)\n",
        "print(pre)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}