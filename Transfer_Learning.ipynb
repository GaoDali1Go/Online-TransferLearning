{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAkWeHOXDZxm",
        "colab_type": "text"
      },
      "source": [
        "# TRANSFER LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ57pYNGDjeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This should be ran for any possible imports that may need to be done.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import requests\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers.core import Dense, Activation, Reshape\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "\n",
        "\n",
        "def expand_categories(values):\n",
        "    result = []\n",
        "    s = values.value_counts()\n",
        "    t = float(len(values))\n",
        "    for v in s.index:\n",
        "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
        "    return \"[{}]\".format(\",\".join(result))\n",
        "        \n",
        "def analyze(df):\n",
        "    print()\n",
        "    cols = df.columns.values\n",
        "    total = float(len(df))\n",
        "    print(\"{} rows\".format(int(total)))\n",
        "    for col in cols:\n",
        "        uniques = df[col].unique()\n",
        "        unique_count = len(uniques)\n",
        "        if unique_count>100:\n",
        "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
        "        else:\n",
        "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
        "            expand_categories(df[col])\n",
        "\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "    df[name] = (df[name]-mean)/sd\n",
        "    \n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = f\"{name}-{x}\"\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "      if x != target:\n",
        "        result.append(x)\n",
        "    res1 = df[result].values \n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return res1.astype(np.float32), dummies.to_numpy().astype(np.float32)\n",
        "    else:\n",
        "        return res1.astype(np.float32), df[target].to_numpy().astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dl0pCaxC9zf",
        "colab_type": "text"
      },
      "source": [
        "# TRANSFER LEARNING: KDD-99 TO UNSW-NB15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHP5ITTQVOBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------------------------------------------------IMPORTING THE KDD99 DATASET-------------------------------------------\n",
        "df = pd.read_csv(\"/content/drive/My Drive/TFG/kddcup.data.corrected\", header=None)\n",
        "df.columns = [\n",
        "    'duration', 'protocol_type', 'service','flag','src_bytes','dst_bytes',\n",
        "    'land','wrong_fragment','urgent','hot','num_failed_logins','logged_in',\n",
        "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
        "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
        "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
        "    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'outcome'\n",
        "]\n",
        "\n",
        "df.dropna(inplace=True, axis=1) #For now, just remove all NaN values\n",
        "display(df[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItF0Rzx-GW_O",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sde_diTvA8Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------------------------------------------------DATA PREPROCESSING-------------------------------------------\n",
        "encode_numeric_zscore(df, 'duration')\n",
        "encode_text_dummy(df, 'protocol_type')\n",
        "encode_text_dummy(df, 'service')\n",
        "encode_text_dummy(df, 'flag')\n",
        "encode_numeric_zscore(df, 'src_bytes')\n",
        "encode_numeric_zscore(df, 'dst_bytes')\n",
        "encode_text_dummy(df, 'land')\n",
        "encode_numeric_zscore(df, 'wrong_fragment')\n",
        "encode_numeric_zscore(df, 'urgent')\n",
        "encode_numeric_zscore(df, 'hot')\n",
        "encode_numeric_zscore(df, 'num_failed_logins')\n",
        "encode_text_dummy(df, 'logged_in')\n",
        "encode_numeric_zscore(df, 'num_compromised')\n",
        "encode_numeric_zscore(df, 'root_shell')\n",
        "encode_numeric_zscore(df, 'su_attempted')\n",
        "encode_numeric_zscore(df, 'num_root')\n",
        "encode_numeric_zscore(df, 'num_file_creations')\n",
        "encode_numeric_zscore(df, 'num_shells')\n",
        "encode_numeric_zscore(df, 'num_access_files')\n",
        "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
        "encode_text_dummy(df, 'is_host_login')\n",
        "encode_text_dummy(df, 'is_guest_login')\n",
        "encode_numeric_zscore(df, 'count')\n",
        "encode_numeric_zscore(df, 'srv_count')\n",
        "encode_numeric_zscore(df, 'serror_rate')\n",
        "encode_numeric_zscore(df, 'srv_serror_rate')\n",
        "encode_numeric_zscore(df, 'rerror_rate')\n",
        "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
        "encode_numeric_zscore(df, 'same_srv_rate')\n",
        "encode_numeric_zscore(df, 'diff_srv_rate')\n",
        "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_count')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
        "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
        "df['outcome'] = np.where(df['outcome']=='normal.', 0, 1)\n",
        "df['outcome'] = pd.to_numeric(df['outcome'])\n",
        "\n",
        "df.dropna(inplace=True, axis=1) #ES TOTALMENTE NECESARIO, AUNQUE NO LO PAREZCA\n",
        "\n",
        "x_columns = df.columns.drop('outcome')\n",
        "x = df[x_columns].values\n",
        "dummies = pd.get_dummies(df['outcome'])\n",
        "y = dummies.values\n",
        "print(\"Done\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok99bR2NGZJg",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz_EYc3UcFq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
        "# Create neural net\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "model.add(Dense(y.shape[1],activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "                        patience=5, verbose=1, mode='auto')\n",
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "          callbacks=[monitor],verbose=1,epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaDoK7lk6HXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtains measurements\n",
        "pred = model.predict(x_test)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "y_eval = np.argmax(y_test,axis=1)\n",
        "score = metrics.accuracy_score(y_eval, pred)\n",
        "roc = metrics.roc_auc_score(y_eval, pred)\n",
        "f1 = metrics.f1_score(y_eval, pred)\n",
        "recall = metrics.recall_score(y_eval, pred)\n",
        "conf = metrics.confusion_matrix(y_eval, pred)\n",
        "model.summary()\n",
        "print(\"Validation score: {}\".format(score))\n",
        "print(roc)\n",
        "print(f1)\n",
        "print(recall)\n",
        "labels = [0,1]\n",
        "df_cm = pd.DataFrame(conf, index = [i for i in labels],\n",
        "                  columns = [i for i in labels])\n",
        "plt.figure(figsize = (5,3))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC4Fd89hBWB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sets a copy of the previously trained model as backup\n",
        "model2 = Sequential()\n",
        "for layer in model.layers:\n",
        "    model2.add(layer)\n",
        "pred = model2.predict(x)\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "expected_classes = np.argmax(y,axis=1)\n",
        "correct = accuracy_score(expected_classes,predict_classes)\n",
        "model2.summary()\n",
        "print(f\"Training Accuracy: {correct}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBELAEMgGrxQ",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxWsE13DKBDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------------------------------------------Working with the UNSW15 Dataset---------------------------------------------\n",
        "col_names = [\n",
        "    'srcip', 'sport', 'dstip', 'dsport','proto','state','dur','sbytes',\n",
        "    'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
        "    'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz',\n",
        "    'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt',\n",
        "    'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
        "    'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst',\n",
        "    'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm','ct_dst_sport_ltm',\n",
        "    'ct_dst_src_ltm','attack_cat', 'label'\n",
        "]\n",
        "#Imports the dataset\n",
        "df1 = pd.read_csv('UNSW-NB15_1.csv', header=0, names=col_names)\n",
        "df2 = pd.read_csv('UNSW-NB15_2.csv', header=0, names=col_names)\n",
        "df3 = pd.read_csv('UNSW-NB15_3.csv', header=0, names=col_names)\n",
        "df4 = pd.read_csv('UNSW-NB15_4.csv', header=0, names=col_names)\n",
        "df = pd.concat([df1,df2,df3,df4], ignore_index = True)\n",
        "\n",
        "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "#Correcting the data\n",
        "\n",
        "for name in col_names:\n",
        "  df[name].replace('', np.nan, inplace=True)\n",
        "  df[name].replace(' ', np.nan, inplace=True)\n",
        "  if name == 'sport' or name == 'dsport':\n",
        "    df[name].replace('-', np.nan, inplace=True)\n",
        "    index = 0\n",
        "    for i in df[name]:\n",
        "      istr = str(i)\n",
        "      if isinstance(i, str) and '0x' in istr:\n",
        "        x = int(i, 16)\n",
        "        df.at[index, name] = x\n",
        "      index += 1\n",
        "\n",
        "df['sport'] = pd.to_numeric(df['sport'])\n",
        "df['dsport'] = pd.to_numeric(df['dsport'])\n",
        "df['ct_ftp_cmd'] = pd.to_numeric(df['ct_ftp_cmd'])\n",
        "\n",
        "for name in col_names:\n",
        "    if name == 'srcip' or name == 'dstip' or name == 'proto' or name == 'state' or name == 'service':\n",
        "        df[name].fillna(\"None\", inplace=True)\n",
        "    elif name == 'attack_cat':\n",
        "        df['attack_cat'].fillna(\"Not an Attack\", inplace=True)\n",
        "        continue\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "#Encoding the data\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "encode_text_dummy(df, 'srcip')\n",
        "encode_text_index(df,'sport')\n",
        "encode_text_dummy(df, 'dstip')\n",
        "encode_text_index(df,'dsport')\n",
        "encode_text_dummy(df, 'proto')\n",
        "encode_text_dummy(df, 'state')\n",
        "encode_numeric_zscore(df,'dur')\n",
        "encode_numeric_zscore(df,'sbytes')\n",
        "encode_numeric_zscore(df,'dbytes')\n",
        "encode_numeric_zscore(df,'sttl')\n",
        "encode_numeric_zscore(df,'dttl')\n",
        "encode_numeric_zscore(df,'sloss')\n",
        "encode_numeric_zscore(df,'dloss')\n",
        "encode_text_dummy(df, 'service')\n",
        "encode_numeric_zscore(df,'Sload')\n",
        "encode_numeric_zscore(df,'Dload')\n",
        "encode_numeric_zscore(df,'Spkts')\n",
        "encode_numeric_zscore(df,'Dpkts')\n",
        "encode_numeric_zscore(df,'swin')\n",
        "encode_numeric_zscore(df,'dwin')\n",
        "encode_numeric_zscore(df,'stcpb')\n",
        "encode_numeric_zscore(df,'dtcpb')\n",
        "encode_numeric_zscore(df,'smeansz')\n",
        "encode_numeric_zscore(df,'dmeansz')\n",
        "encode_numeric_zscore(df,'trans_depth')\n",
        "encode_numeric_zscore(df,'res_bdy_len')\n",
        "encode_numeric_zscore(df,'Sjit')\n",
        "encode_numeric_zscore(df,'Djit')\n",
        "encode_numeric_zscore(df,'Sintpkt')\n",
        "encode_numeric_zscore(df,'Dintpkt')\n",
        "encode_numeric_zscore(df,'tcprtt')\n",
        "encode_numeric_zscore(df,'synack')\n",
        "encode_numeric_zscore(df,'ackdat')\n",
        "encode_text_dummy(df, 'is_sm_ips_ports')\n",
        "encode_numeric_zscore(df,'ct_state_ttl')\n",
        "encode_numeric_zscore(df,'ct_flw_http_mthd')\n",
        "encode_text_dummy(df, 'is_ftp_login')\n",
        "encode_text_index(df,'ct_ftp_cmd')\n",
        "encode_numeric_zscore(df,'ct_srv_src')\n",
        "encode_numeric_zscore(df,'ct_srv_dst')\n",
        "encode_numeric_zscore(df,'ct_dst_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_dport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_sport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_src_ltm')\n",
        "encode_text_dummy(df, 'attack_cat')\n",
        "outcomes = encode_text_index(df, 'label')\n",
        "num_classes = len(outcomes)\n",
        "\n",
        "df.dropna(inplace=True, axis=0) # For now, just drop NA's (rows with missing values)\n",
        "\n",
        "# Break into X (predictors) & y (prediction)\n",
        "x, y = to_xy(df,'label')\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cJjXTFlGc9G",
        "colab_type": "text"
      },
      "source": [
        "##Transfering and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYUJbihIBLpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = Sequential()\n",
        "for i in range(5):\n",
        "  if i == 0:\n",
        "    #Adds the new input layer to the model\n",
        "    layer = Dense(125, input_dim=x.shape[1], activation='relu')\n",
        "    model3.add(layer)\n",
        "  layer = model.layers[i]\n",
        "  layer.trainable = False\n",
        "  model3.add(layer)\n",
        "#Now we add the output layer\n",
        "model3.add(Dense(2,activation='softmax'))\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model3.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor],verbose=1,epochs=1000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtdskpdNaMcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get metrics from the model and plots the confusion matrix\n",
        "pred = model3.predict(x_test)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "y_eval = np.argmax(y_test,axis=1)\n",
        "score = metrics.accuracy_score(y_eval, pred)\n",
        "roc = metrics.roc_auc_score(y_eval, pred)\n",
        "f1 = metrics.f1_score(y_eval, pred)\n",
        "recall = metrics.recall_score(y_eval, pred)\n",
        "conf = metrics.confusion_matrix(y_eval, pred)\n",
        "model.summary()\n",
        "\n",
        "print(\"Validation score: {}\".format(score))\n",
        "print(roc)\n",
        "print(f1)\n",
        "print(recall)\n",
        "\n",
        "labels = [0,1]\n",
        "df_cm = pd.DataFrame(conf, index = [i for i in labels],\n",
        "                  columns = [i for i in labels])\n",
        "plt.figure(figsize = (5,3))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-vvAYzdGu4v",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjeWYDDmjhUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------------------------------------------UNSW-NB15 using only the relevant features\n",
        "col_names = [\n",
        "    'srcip', 'sport', 'dstip', 'dsport','proto','state','dur','sbytes',\n",
        "    'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
        "    'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz',\n",
        "    'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt',\n",
        "    'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
        "    'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst',\n",
        "    'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm','ct_dst_sport_ltm',\n",
        "    'ct_dst_src_ltm','attack_cat', 'label'\n",
        "]\n",
        "#Imports the dataset\n",
        "df1 = pd.read_csv('UNSW-NB15_1.csv', header=0, names=col_names)\n",
        "df2 = pd.read_csv('UNSW-NB15_2.csv', header=0, names=col_names)\n",
        "df3 = pd.read_csv('UNSW-NB15_3.csv', header=0, names=col_names)\n",
        "df4 = pd.read_csv('UNSW-NB15_4.csv', header=0, names=col_names)\n",
        "df = pd.concat([df1,df2,df3,df4], ignore_index = True)\n",
        "\n",
        "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "#Corrects the dataset\n",
        "\n",
        "for name in col_names:\n",
        "  if name == 'sport' or name == 'dsport':\n",
        "    df[name].replace('-', np.nan, inplace=True)\n",
        "    index = 0\n",
        "    for i in df[name]:\n",
        "      istr = str(i)\n",
        "      if isinstance(i, str) and '0x' in istr:\n",
        "        x = int(i, 16)\n",
        "        df.at[index, name] = x\n",
        "      index += 1\n",
        "\n",
        "df['sport'] = pd.to_numeric(df['sport'])\n",
        "df['dsport'] = pd.to_numeric(df['dsport'])\n",
        "df['ct_ftp_cmd'] = pd.to_numeric(df['ct_ftp_cmd'])\n",
        "print(\"done\")\n",
        "\n",
        "#Time to encode\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "df.drop('srcip', axis=1, inplace=True)\n",
        "df.drop('sport', axis=1, inplace=True)\n",
        "df.drop('dstip', axis=1, inplace=True)\n",
        "df.drop('dsport', axis=1, inplace=True)\n",
        "encode_text_index(df, 'proto')\n",
        "encode_text_index(df, 'state')\n",
        "encode_numeric_zscore(df,'dur')\n",
        "encode_numeric_zscore(df,'sbytes')\n",
        "encode_numeric_zscore(df,'dbytes')\n",
        "encode_numeric_zscore(df,'sttl')\n",
        "encode_numeric_zscore(df,'dttl')\n",
        "encode_numeric_zscore(df,'sloss')\n",
        "encode_numeric_zscore(df,'dloss')\n",
        "encode_text_index(df, 'service')\n",
        "encode_numeric_zscore(df,'Sload')\n",
        "encode_numeric_zscore(df,'Dload')\n",
        "encode_numeric_zscore(df,'Spkts')\n",
        "encode_numeric_zscore(df,'Dpkts')\n",
        "encode_numeric_zscore(df,'swin')\n",
        "encode_numeric_zscore(df,'dwin')\n",
        "encode_numeric_zscore(df,'stcpb')\n",
        "encode_numeric_zscore(df,'dtcpb')\n",
        "encode_numeric_zscore(df,'smeansz')\n",
        "encode_numeric_zscore(df,'dmeansz')\n",
        "encode_numeric_zscore(df,'trans_depth')\n",
        "encode_numeric_zscore(df,'res_bdy_len')\n",
        "encode_numeric_zscore(df,'Sjit')\n",
        "encode_numeric_zscore(df,'Djit')\n",
        "encode_numeric_zscore(df,'Sintpkt')\n",
        "encode_numeric_zscore(df,'Dintpkt')\n",
        "encode_numeric_zscore(df,'tcprtt')\n",
        "encode_numeric_zscore(df,'synack')\n",
        "encode_numeric_zscore(df,'ackdat')\n",
        "encode_numeric_zscore(df,'ct_state_ttl')\n",
        "encode_numeric_zscore(df,'ct_flw_http_mthd')\n",
        "encode_text_index(df, 'is_ftp_login')\n",
        "encode_text_index(df,'ct_ftp_cmd')\n",
        "encode_numeric_zscore(df,'ct_srv_src')\n",
        "encode_numeric_zscore(df,'ct_srv_dst')\n",
        "encode_numeric_zscore(df,'ct_dst_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_ ltm')\n",
        "encode_numeric_zscore(df,'ct_src_dport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_sport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_src_ltm')\n",
        "#Gets rid of the multiclass label\n",
        "df.drop('attack_cat', axis=1, inplace=True)\n",
        "\n",
        "x, y = to_xy(df,'label')\n",
        "x_columns = ['sttl', 'Dload', 'Spkts', 'sloss', 'dloss', 'ct_src_ltm', 'ct_src_ltm',\n",
        "             'ct_srv_dst']\n",
        "x = df[x_columns]\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.25, random_state=42)\n",
        "print(x_train)\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpQxMlmIGisY",
        "colab_type": "text"
      },
      "source": [
        "## Transfering and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpA6iQLOdy5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model for the relevant features\n",
        "model4 = Sequential()\n",
        "\n",
        "for i in range(5):\n",
        "  if i == 0:\n",
        "    layer = Dense(10, input_dim=x.shape[1], activation='relu')\n",
        "    model4.add(layer)\n",
        "    continue\n",
        "  layer = model.layers[i]\n",
        "  layer.trainable = False\n",
        "  model4.add(layer)\n",
        "#Now we add the output\n",
        "model4.add(Dense(y.shape[1],activation='softmax'))\n",
        "model4.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model4.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor],verbose=1,epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv7WX6OnjLuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get metrics from the model and plots the confusion matrix\n",
        "pred = model4.predict(x_test)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "y_eval = np.argmax(y_test,axis=1)\n",
        "score = metrics.accuracy_score(y_eval, pred)\n",
        "roc = metrics.roc_auc_score(y_eval, pred)\n",
        "f1 = metrics.f1_score(y_eval, pred)\n",
        "recall = metrics.recall_score(y_eval, pred)\n",
        "conf = metrics.confusion_matrix(y_eval, pred)\n",
        "model.summary()\n",
        "print(\"Validation score: {}\".format(score))\n",
        "print(roc)\n",
        "print(f1)\n",
        "print(recall)\n",
        "labels = [0,1]\n",
        "df_cm = pd.DataFrame(conf, index = [i for i in labels],\n",
        "                  columns = [i for i in labels])\n",
        "plt.figure(figsize = (5,3))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jn4hM7mFDOQ",
        "colab_type": "text"
      },
      "source": [
        "#TRANSFER LEARNING: UNSW-NB15 TO KDD-99"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o5VH-E3ikaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_names = [\n",
        "    'srcip', 'sport', 'dstip', 'dsport','proto','state','dur','sbytes',\n",
        "    'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
        "    'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz',\n",
        "    'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt',\n",
        "    'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
        "    'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst',\n",
        "    'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm','ct_dst_sport_ltm',\n",
        "    'ct_dst_src_ltm','attack_cat', 'label'\n",
        "]\n",
        "#Imports the dataset\n",
        "df1 = pd.read_csv('UNSW-NB15_1.csv', header=0, names=col_names)\n",
        "df2 = pd.read_csv('UNSW-NB15_2.csv', header=0, names=col_names)\n",
        "df3 = pd.read_csv('UNSW-NB15_3.csv', header=0, names=col_names)\n",
        "df4 = pd.read_csv('UNSW-NB15_4.csv', header=0, names=col_names)\n",
        "df = pd.concat([df1,df2,df3,df4], ignore_index = True)\n",
        "\n",
        "display(df[0:5])\n",
        "\n",
        "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhtdsd_x33H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Corrects the dataset\n",
        "for name in col_names:\n",
        "  if name == 'sport' or name == 'dsport':\n",
        "    df[name].replace('-', np.nan, inplace=True)\n",
        "    index = 0\n",
        "    for i in df[name]:\n",
        "      istr = str(i)\n",
        "      if isinstance(i, str) and '0x' in istr:\n",
        "        x = int(i, 16)\n",
        "        df.at[index, name] = x\n",
        "      index += 1\n",
        "\n",
        "df['sport'] = pd.to_numeric(df['sport'])\n",
        "df['dsport'] = pd.to_numeric(df['dsport'])\n",
        "df['ct_ftp_cmd'] = pd.to_numeric(df['ct_ftp_cmd'])\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siYa12mAGDSO",
        "colab_type": "text"
      },
      "source": [
        "###Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEDgGfD7mRDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding the dataset\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "df.drop('srcip', axis=1, inplace=True)\n",
        "df.drop('sport', axis=1, inplace=True)\n",
        "df.drop('dstip', axis=1, inplace=True)\n",
        "df.drop('dsport', axis=1, inplace=True)\n",
        "encode_text_index(df, 'proto')\n",
        "encode_text_index(df, 'state')\n",
        "encode_numeric_zscore(df,'dur')\n",
        "encode_numeric_zscore(df,'sbytes')\n",
        "encode_numeric_zscore(df,'dbytes')\n",
        "encode_numeric_zscore(df,'sttl')\n",
        "encode_numeric_zscore(df,'dttl')\n",
        "encode_numeric_zscore(df,'sloss')\n",
        "encode_numeric_zscore(df,'dloss')\n",
        "encode_text_index(df, 'service')\n",
        "encode_numeric_zscore(df,'Sload')\n",
        "encode_numeric_zscore(df,'Dload')\n",
        "encode_numeric_zscore(df,'Spkts')\n",
        "encode_numeric_zscore(df,'Dpkts')\n",
        "encode_numeric_zscore(df,'swin')\n",
        "encode_numeric_zscore(df,'dwin')\n",
        "encode_numeric_zscore(df,'stcpb')\n",
        "encode_numeric_zscore(df,'dtcpb')\n",
        "encode_numeric_zscore(df,'smeansz')\n",
        "encode_numeric_zscore(df,'dmeansz')\n",
        "encode_numeric_zscore(df,'trans_depth')\n",
        "encode_numeric_zscore(df,'res_bdy_len')\n",
        "encode_numeric_zscore(df,'Sjit')\n",
        "encode_numeric_zscore(df,'Djit')\n",
        "encode_numeric_zscore(df,'Sintpkt')\n",
        "encode_numeric_zscore(df,'Dintpkt')\n",
        "encode_numeric_zscore(df,'tcprtt')\n",
        "encode_numeric_zscore(df,'synack')\n",
        "encode_numeric_zscore(df,'ackdat')\n",
        "encode_numeric_zscore(df,'ct_state_ttl')\n",
        "encode_numeric_zscore(df,'ct_flw_http_mthd')\n",
        "encode_text_index(df, 'is_ftp_login')\n",
        "encode_text_index(df,'ct_ftp_cmd')\n",
        "encode_numeric_zscore(df,'ct_srv_src')\n",
        "encode_numeric_zscore(df,'ct_srv_dst')\n",
        "encode_numeric_zscore(df,'ct_dst_ltm')\n",
        "encode_numeric_zscore(df,'ct_src_ ltm')\n",
        "encode_numeric_zscore(df,'ct_src_dport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_sport_ltm')\n",
        "encode_numeric_zscore(df,'ct_dst_src_ltm')\n",
        "df.drop('attack_cat', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RItvPdcBN5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(inplace=True, axis=0) # For now, just drop NA's (rows with missing values)\n",
        "# Break into X (predictors) & y (prediction)\n",
        "x, y = to_xy(df,'label')\n",
        "x_columns = ['sttl', 'Dload', 'Spkts', 'sloss', 'dloss', 'ct_src_ ltm', 'ct_src_ ltm',\n",
        "             'ct_srv_dst']\n",
        "x = df[x_columns]\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.25, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEDsj6oOGGbJ",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwjAuXpBkWm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TRAIN UNSW15 FIRST-----------------------------------------------------------------------------------------------------------------------m02_R4_G4_tanh\")\n",
        "model11 = Sequential()\n",
        "model11.add(Dense(47, input_dim=x.shape[1], activation='relu'))\n",
        "model11.add(Dense(42, activation='tanh'))\n",
        "model11.add(Dense(10, activation='tanh'))\n",
        "#model11.add(Dense(1, kernel_initializer='normal'))\n",
        "model11.add(Dense(y.shape[1], activation='softmax'))\n",
        "model11.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
        "model11.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=1,epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXPknj0p9QJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gets the metrics and prints the confusion matrix\n",
        "pred = model11.predict(x_test)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "y_eval = np.argmax(y_test,axis=1)\n",
        "score = metrics.accuracy_score(y_eval, pred)\n",
        "roc = metrics.roc_auc_score(y_eval, pred)\n",
        "f1 = metrics.f1_score(y_eval, pred)\n",
        "recall = metrics.recall_score(y_eval, pred)\n",
        "conf = metrics.confusion_matrix(y_eval, pred)\n",
        "model11.summary()\n",
        "print(\"Validation score: {}\".format(score))\n",
        "print(roc)\n",
        "print(f1)\n",
        "print(recall)\n",
        "labels = [0,1]\n",
        "df_cm = pd.DataFrame(conf, index = [i for i in labels],\n",
        "                  columns = [i for i in labels])\n",
        "plt.figure(figsize = (5,3))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QfVRtKCnX8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#First we copy the previous model as backup. We try it out, see if it works.\n",
        "modelTemp = Sequential()\n",
        "for layer in model11.layers:\n",
        "    modelTemp.add(layer)\n",
        "pred = modelTemp.predict(x)\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "expected_classes = np.argmax(y,axis=1)\n",
        "correct = accuracy_score(expected_classes,predict_classes)\n",
        "modelTemp.summary()\n",
        "print(f\"Training Accuracy: {correct}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2vkYBr3GLzS",
        "colab_type": "text"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kaw_MfscnwQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------------------------------------------------Handling KDD99 data just like before-------------------------------------------\n",
        "df = pd.read_csv(\"/content/drive/My Drive/TFG/kddcup.data.corrected\", header=None)\n",
        "df.columns = [\n",
        "    'duration', 'protocol_type', 'service','flag','src_bytes','dst_bytes',\n",
        "    'land','wrong_fragment','urgent','hot','num_failed_logins','logged_in',\n",
        "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
        "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
        "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
        "    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'outcome'\n",
        "]\n",
        "\n",
        "df.dropna(inplace=True, axis=1)\n",
        "\n",
        "encode_numeric_zscore(df, 'duration')\n",
        "encode_text_dummy(df, 'protocol_type')\n",
        "encode_text_dummy(df, 'service')\n",
        "encode_text_dummy(df, 'flag')\n",
        "encode_numeric_zscore(df, 'src_bytes')\n",
        "encode_numeric_zscore(df, 'dst_bytes')\n",
        "encode_text_dummy(df, 'land')\n",
        "encode_numeric_zscore(df, 'wrong_fragment')\n",
        "encode_numeric_zscore(df, 'urgent')\n",
        "encode_numeric_zscore(df, 'hot')\n",
        "encode_numeric_zscore(df, 'num_failed_logins')\n",
        "encode_text_dummy(df, 'logged_in')\n",
        "encode_numeric_zscore(df, 'num_compromised')\n",
        "encode_numeric_zscore(df, 'root_shell')\n",
        "encode_numeric_zscore(df, 'su_attempted')\n",
        "encode_numeric_zscore(df, 'num_root')\n",
        "encode_numeric_zscore(df, 'num_file_creations')\n",
        "encode_numeric_zscore(df, 'num_shells')\n",
        "encode_numeric_zscore(df, 'num_access_files')\n",
        "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
        "encode_text_dummy(df, 'is_host_login')\n",
        "encode_text_dummy(df, 'is_guest_login')\n",
        "encode_numeric_zscore(df, 'count')\n",
        "encode_numeric_zscore(df, 'srv_count')\n",
        "encode_numeric_zscore(df, 'serror_rate')\n",
        "encode_numeric_zscore(df, 'srv_serror_rate')\n",
        "encode_numeric_zscore(df, 'rerror_rate')\n",
        "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
        "encode_numeric_zscore(df, 'same_srv_rate')\n",
        "encode_numeric_zscore(df, 'diff_srv_rate')\n",
        "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_count')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
        "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
        "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
        "\n",
        "df.dropna(inplace=True,axis=1)\n",
        "df['outcome'] = np.where(df['outcome']=='normal.', 0, 1)\n",
        "df['outcome'] = pd.to_numeric(df['outcome'])\n",
        "\n",
        "x, y = to_xy(df, 'outcome')\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vVxlme3GQJc",
        "colab_type": "text"
      },
      "source": [
        "##Transfering and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M-VS1fdJlQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model5 = Sequential()\n",
        "for i in range(4):\n",
        "  if i == 0:\n",
        "    layer = Dense(47, input_dim=x.shape[1], activation='relu')\n",
        "    model5.add(layer)\n",
        "    continue\n",
        "  layer = modelTemp.layers[i]\n",
        "  layer.trainable = False\n",
        "  model5.add(layer)\n",
        "#Now we add the output\n",
        "model5.add(Dense(y.shape[1], activation='softmax'))\n",
        "model5.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model5.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor],verbose=1,epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpgziRxHCeXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gets metrics for the model and plots the confusion matrix\n",
        "pred = model5.predict(x_test)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "y_eval = np.argmax(y_test,axis=1)\n",
        "score = metrics.accuracy_score(y_eval, pred)\n",
        "roc = metrics.roc_auc_score(y_eval, pred)\n",
        "f1 = metrics.f1_score(y_eval, pred)\n",
        "recall = metrics.recall_score(y_eval, pred)\n",
        "conf = metrics.confusion_matrix(y_eval, pred)\n",
        "model.summary()\n",
        "print(\"Validation score: {}\".format(score))\n",
        "print(roc)\n",
        "print(f1)\n",
        "print(recall)\n",
        "labels = [0,1]\n",
        "df_cm = pd.DataFrame(conf, index = [i for i in labels],\n",
        "                  columns = [i for i in labels])\n",
        "plt.figure(figsize = (5,3))\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}